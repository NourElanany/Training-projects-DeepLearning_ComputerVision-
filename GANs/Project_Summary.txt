Project Name: GANs (Generative Adversarial Networks)

Description:
This project explores the fascinating world of Generative AI using Generative Adversarial Networks (GANs). It consists of two main modules:
1.  **MNIST DCGAN**: A Deep Convolutional GAN trained to generate realistic handwritten digits.
2.  **Anime GAN**: A more advanced GAN model trained on a large dataset of anime faces to generate novel characters.
The project demonstrates the power of adversarial training where two neural networks (Generator and Discriminator) compete against each other to improve generation quality.

Methodology (What happened):
1.  **Dataset Preparation**:
    -   **MNIST**: Loaded ~60,000 grayscale images of digits, normalized to [-1, 1].
    -   **Anime**: Processed a dataset of ~63,565 color anime faces (`animefacedataset`), resizing and normalizing them.
2.  **Model Architecture**:
    -   **Generator**: Uses `Conv2DTranspose` (Upsampling) layers with Batch Normalization and LeakyReLU/ReLU activations to transform random noise vectors into images.
    -   **Discriminator**: A Convolutional Neural Network (CNN) based classifier using `Conv2D` and LeakyReLU layers to distinguish between real dataset images and fake generated ones.
3.  **Training Process**: Implemented the Minimax game training loop. The Discriminator is trained to maximize classification accuracy (Real vs. Fake), while the Generator is trained to minimize the Discriminator's ability to classify fakes correctly.
4.  **Loss Function**: Utilized Binary Cross-Entropy loss for both networks.

Benefits:
-   **Synthetic Data Generation**: Capable of creating unlimited unique samples, useful for data augmentation.
-   **Unsupervised Learning**: Learns complex data distributions without requiring manual labeling.
-   **Creative Application**: Demonstrates the ability of AI to generate artistic content (anime characters).

Accuracy:
-   **N/A (Generative Task)**: Unlike classification, GANs don't have a single "accuracy" metric. Success is measured by the visual quality and diversity of generated images.
-   **Visual Quality**:
    -   **MNIST**: By Epoch 50, the model generates distinct, legible digits resembling the training data.
    -   **Anime**: The model successfully captures facial features and anime artistic styles from the dataset.
-   **Training Dynamics**: Monitored Generator and Discriminator losses to ensure neither overpowered the other (preventing mode collapse).

Learnings:
-   Building and tuning Deep Convolutional GANs (DCGANs) using TensorFlow/Keras.
-   Understanding Transposed Convolutions for image upscaling.
-   Managing the delicate balance of adversarial training stability.
-   Working with large image datasets using `tf.data` pipelines.
